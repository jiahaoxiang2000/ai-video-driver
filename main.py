"""
Enhanced FireRedTTS2 main script with modular video generation pipeline.

This script generates conversational speech using FireRedTTS2, creates synchronized
video animations with Manim, and combines everything into a final video output.
"""

import sys
import time
import argparse
import os
from typing import Optional, List, Dict, Any
from pathlib import Path

from fireredtts2.fireredtts2 import FireRedTTS2
from ai_video_driver import (
    generate_video_from_srt,
    combine_audio_video,
    create_output_structure,
    save_files,
    setup_pipeline_logging,
    PipelineTimer,
    log_file_info,
    config,
)
from ai_video_driver.content_fetcher import GitHubContentFetcher
from ai_video_driver.podcast_converter import PodcastConverter

# Global voice prompt configuration
PROMPT_WAV_LIST = [
    "audio/S1.flac",
    "audio/S2.wav",
]

# "audio/S1.wav", ourself
# "[S1]ç„¶åï¼Œé¢å¤–å†è®²ä¸€ä¸‹ï¼Œå°±æ˜¯ä»–æœ‰ä¸€ä¸ªï¼Œè¿™ä¸ªï¼Œä»–è¿™ä¸ªæ’ä»¶æœ‰ä¸€ä¸ªå¯ä»¥è‡ªå®šä¹‰å®ƒçš„ä¸€ä¸ªjson",

# "audio/mid-man.wav"
# "[S1]é‚£æˆ‘è¿™é‡Œä¸»è¦æ˜¯focusçš„æ˜¯è‹±æ–‡podcastï¼Œé‚£å¾ˆå¤šè§‚ä¼—å¬åˆ°è¿™é‡Œå¯èƒ½ä¼šè§‰å¾—è‡ªå·±è‹±æ–‡æ°´å¹³ä¸å¥½ï¼Œä¸æ•¢æ”¶å¬çº¯è‹±æ–‡èŠ‚ç›®,é‚£è¿™é‡Œæˆ‘æƒ³å‘Šè¯‰ä½ ",


PROMPT_TEXT_LIST = [
    "[S1]å•Šï¼Œå¯èƒ½è¯´æ›´é€‚åˆç¾å›½å¸‚åœºåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚é‚£è¿™è¿™ä¸ªå¯èƒ½è¯´ï¼Œå½“ç„¶å¦‚æœè¯´æœ‰æœ‰æœºä¼šèƒ½äº²èº«çš„å»è€ƒå¯Ÿå»äº†è§£ä¸€ä¸‹ï¼Œé‚£å½“ç„¶æ˜¯æœ‰æ›´å¥½çš„å¸®åŠ©ã€‚",
    "[S2]ä»å‰§åœºè½¬å½±è§†ä¹‹åæœ‰ä»€ä¹ˆå·®åˆ«ï¼Œç„¶åä½ çš„é€‚åº”å‘€ç­‰ç­‰ï¼Œä½ è§‰å¾—ä½ åšäº†ä»€ä¹ˆæ ·çš„è°ƒè¯•ã€‚",
]


def get_default_dialogue():
    """Default dialogue content about FireRedTTS2"""
    return [
        "[S1]å—¯ï¼Œæœ€è¿‘å‘ç°äº†ä¸€ä¸ªå¾ˆå‰å®³çš„TTSç³»ç»Ÿå«FireRedTTS2ã€‚å®ƒæœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯å¯ä»¥generate long conversational speechï¼Œæ”¯æŒmulti-speaker dialogue generationã€‚",
        "[S2]çœŸçš„å—ï¼Ÿé‚£å®ƒè·Ÿå…¶ä»–çš„TTSæœ‰ä»€ä¹ˆä¸åŒå‘¢ï¼Ÿ",
        "[S1]è¿™ä¸ªsystemå¾ˆç‰¹åˆ«ï¼Œå®ƒå¯ä»¥æ”¯æŒ3åˆ†é’Ÿçš„dialogue with 4 speakersï¼Œè€Œä¸”è¿˜æœ‰ultra-low latencyã€‚åœ¨L20 GPUä¸Šï¼Œfirst-packet latencyåªè¦140msã€‚æœ€é‡è¦çš„æ˜¯å®ƒæ”¯æŒmulti lingualï¼ŒåŒ…æ‹¬Englishã€Chineseã€Japaneseã€Koreanã€Frenchã€Germanè¿˜æœ‰Russianã€‚",
        "[S2]å¬èµ·æ¥å¾ˆpowerfulå•Šã€‚é‚£å®ƒè¿˜æœ‰ä»€ä¹ˆå…¶ä»–featureså—ï¼Ÿ",
        "[S1]å¯¹ï¼Œå®ƒè¿˜æœ‰zero-shot voice cloningåŠŸèƒ½ï¼Œå¯ä»¥åšcross-lingualå’Œcode-switching scenariosã€‚è€Œä¸”è¿˜æœ‰random timbre generationï¼Œè¿™ä¸ªå¯¹creating ASR dataå¾ˆæœ‰ç”¨ã€‚æœ€å…³é”®æ˜¯stabilityå¾ˆå¼ºï¼Œåœ¨monologueå’Œdialogue testsé‡Œéƒ½æœ‰high similarityå’Œlow WER/CERã€‚",
        "[S2]é‚£è¿™ä¸ªæ˜¯open sourceçš„å—ï¼Ÿ",
        "[S1]æ˜¯çš„ï¼Œå®ƒåŸºäºApache 2.0 licenseã€‚ä½ å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°FireRedTeam/FireRedTTS2ï¼Œè¿˜æœ‰pre-trained checkpointsåœ¨Hugging Faceä¸Šã€‚ä¸è¿‡è¦æ³¨æ„ï¼Œvoice cloningåŠŸèƒ½åªèƒ½ç”¨äºacademic research purposesã€‚",
    ]


def generate_content_from_repo(
    repo_url: str, style: str, length: str, github_token: Optional[str] = None
) -> list:
    """Generate dialogue content from a GitHub repository"""
    logger = setup_pipeline_logging()

    try:
        # Initialize content fetcher
        fetcher = GitHubContentFetcher(github_token=github_token)

        # Fetch repository content
        logger.info(f"Fetching content from repository: {repo_url}")
        repo_content = fetcher.fetch_repository_content(repo_url)

        if not repo_content:
            logger.error("Failed to fetch repository content")
            return get_default_dialogue()

        # Convert to podcast format
        converter = PodcastConverter()
        dialogue = converter.convert_to_podcast(
            repo_content, style=style, length=length
        )

        if dialogue and converter.validate_dialogue_format(dialogue):
            logger.info(f"Successfully generated {len(dialogue)} dialogue segments")
            return dialogue
        else:
            logger.warning("Generated dialogue failed validation, using fallback")
            return create_fallback_dialogue(
                {
                    "name": repo_content.get("name", ""),
                    "description": repo_content.get("description", ""),
                    "language": repo_content.get("language", ""),
                    "stargazers_count": repo_content.get("stars", 0),
                }
            )

    except Exception as e:
        logger.error(f"Failed to generate content from repository: {e}")
        return get_default_dialogue()


def get_top5_trending_repos(github_token: Optional[str] = None) -> List[Dict[str, Any]]:
    """Get top 5 unrecorded trending repositories"""
    logger = setup_pipeline_logging()

    try:
        # Initialize content fetcher
        fetcher = GitHubContentFetcher(github_token=github_token)

        # Get top 5 trending repositories
        logger.info("Fetching top 5 unrecorded trending repositories")
        trending_repos = fetcher.get_top5_unrecorded_trending_repos()

        if not trending_repos:
            logger.error("No trending repositories found")
            return []

        logger.info(f"Found {len(trending_repos)} trending repositories")
        for i, repo in enumerate(trending_repos, 1):
            logger.info(
                f"{i}. {repo.get('full_name', 'Unknown')} - {repo.get('stargazers_count', 0)} stars"
            )

        return trending_repos

    except Exception as e:
        logger.error(f"Failed to get trending repositories: {e}")
        return []


def generate_multi_repo_content(
    style: str,
    length: str,
    device: str,
    output_name: str,
    github_token: Optional[str] = None,
) -> bool:
    """Generate content from top 5 trending repos and create combined video"""
    logger = setup_pipeline_logging()

    try:
        # Get top 5 trending repositories
        trending_repos = get_top5_trending_repos(github_token)

        if not trending_repos:
            logger.error("No trending repositories found")
            return False

        logger.info(f"Processing {len(trending_repos)} trending repositories")

        # Create main output directory
        main_output_dir = Path(f"outputs/{output_name}_multi_repo")
        main_output_dir.mkdir(parents=True, exist_ok=True)

        generated_videos = []
        video_titles = []
        repo_dialogues = []

        # Process each repository and collect dialogues
        for i, repo in enumerate(trending_repos, 1):
            repo_name = repo.get("full_name", f"repo_{i}")
            logger.info(f"Processing repository {i}/5: {repo_name}")

            # Convert repo to podcast
            podcast_dialogue = convert_repo_to_podcast(
                repo, style, length, github_token
            )

            if not podcast_dialogue:
                logger.warning(f"Failed to generate podcast for {repo_name}, skipping")
                continue

            # Store dialogue for summary generation
            repo_dialogues.append((repo_name, podcast_dialogue))

            # Generate video for this podcast
            video_file = generate_video_for_podcast(
                podcast_dialogue, repo_name, device, main_output_dir
            )

            if video_file:
                generated_videos.append(video_file)
                video_titles.append(repo_name)
                logger.info(f"Successfully generated video {i}/5 for {repo_name}")
            else:
                logger.warning(f"Failed to generate video for {repo_name}")

        # Generate summary video from collected dialogues
        if repo_dialogues:
            logger.info("Generating summary video from top 5 repositories")
            summary_dialogue = create_summary_dialogue(repo_dialogues)

            summary_video = generate_video_for_podcast(
                summary_dialogue, "summary_introduction", device, main_output_dir
            )

            if summary_video:
                # Insert summary video at the beginning
                generated_videos.insert(0, summary_video)
                video_titles.insert(0, "intro")
                logger.info("Successfully generated summary introduction video")
            else:
                logger.warning("Failed to generate summary video")

        # Combine all videos
        if generated_videos:
            final_combined_video = main_output_dir / "combined_final.mp4"
            success = combine_videos(generated_videos, final_combined_video, video_titles)

            if success:
                logger.info("ğŸ‰ MULTI-REPO PIPELINE COMPLETED SUCCESSFULLY!")
                logger.info(f"ğŸ“ Output directory: {main_output_dir}")
                logger.info(f"ğŸ¬ Combined video: {final_combined_video}")
                logger.info(
                    f"ğŸ“Š Generated {len(generated_videos)} total videos (including summary)"
                )
                print(f"\nğŸ¬ Final combined video: {final_combined_video}")
                print(f"ğŸ“ All files: {main_output_dir}")
                return True
            else:
                logger.error("Failed to combine videos")
                print(f"\nâš ï¸  Video combination failed")
                print(f"ğŸ“ Individual videos: {main_output_dir}")
                return False
        else:
            logger.error("No videos were generated")
            return False

    except Exception as e:
        logger.error(f"Failed to generate multi-repo content: {e}")
        return False


def convert_repo_to_podcast(
    repo_info: Dict[str, Any],
    style: str,
    length: str,
    github_token: Optional[str] = None,
) -> List[str]:
    """Convert a single repository to podcast dialogue"""
    logger = setup_pipeline_logging()

    try:
        # Get repository URL
        repo_url = repo_info.get("html_url")
        if not repo_url:
            logger.error("No repository URL found")
            return get_default_dialogue()

        # Fetch detailed repository content
        fetcher = GitHubContentFetcher(github_token=github_token)
        repo_content = fetcher.fetch_repository_content(repo_url)

        if not repo_content:
            logger.error(
                f"Failed to fetch content for {repo_info.get('full_name', 'Unknown')}"
            )
            return get_default_dialogue()

        # Convert to podcast format
        converter = PodcastConverter()
        dialogue = converter.convert_to_podcast(
            repo_content, style=style, length=length
        )

        if dialogue and converter.validate_dialogue_format(dialogue):
            logger.info(
                f"Successfully converted {repo_info.get('full_name', 'Unknown')} to {len(dialogue)} dialogue segments"
            )

            # Mark repo as recorded
            fetcher.mark_repo_as_recorded(repo_info.get("full_name", ""))

            return dialogue
        else:
            logger.warning(
                f"Generated dialogue failed validation for {repo_info.get('full_name', 'Unknown')}, using fallback"
            )
            # Create a simple fallback dialogue based on repo info
            return create_fallback_dialogue(repo_info)

    except Exception as e:
        logger.error(f"Failed to convert repository to podcast: {e}")
        return get_default_dialogue()


def create_summary_dialogue(repo_dialogues: List[tuple]) -> List[str]:
    """Create a summary dialogue from multiple repository dialogues using AI"""
    logger = setup_pipeline_logging()

    try:
        # Initialize PodcastConverter for AI generation
        converter = PodcastConverter()

        if not converter.check_api_availability():
            logger.warning("AI API not available, using fallback summary")
            return _create_fallback_summary(repo_dialogues)

        # Prepare summary content from all repo dialogues
        summary_content = _prepare_summary_content(repo_dialogues)

        # Generate AI summary dialogue
        summary_dialogue = converter._generate_summary_dialogue(summary_content)

        if summary_dialogue and converter.validate_dialogue_format(summary_dialogue):
            logger.info(
                f"Successfully generated AI summary with {len(summary_dialogue)} segments"
            )
            return summary_dialogue
        else:
            logger.warning("AI summary generation failed, using fallback")
            return _create_fallback_summary(repo_dialogues)

    except Exception as e:
        logger.error(f"Failed to create AI summary dialogue: {e}")
        return _create_fallback_summary(repo_dialogues)


def _prepare_summary_content(repo_dialogues: List[tuple]) -> Dict[str, str]:
    """Prepare content for summary generation"""
    repo_names = [repo_name for repo_name, _ in repo_dialogues]

    # Extract key points from each dialogue
    repo_summaries = []
    for repo_name, dialogue in repo_dialogues:
        # Take first few dialogue segments as key points
        key_points = dialogue[:3] if len(dialogue) >= 3 else dialogue
        repo_summaries.append(
            f"Repository: {repo_name}\nKey discussion points: {' '.join(key_points)}"
        )

    summary_content = {
        "name": "GitHub Top 5 Trending Repositories Summary",
        "description": f"Summary of top 5 trending repositories: {', '.join(repo_names)}",
        "readme": "\n\n".join(repo_summaries),
    }

    return summary_content


def _create_fallback_summary(repo_dialogues: List[tuple]) -> List[str]:
    """Fallback summary when AI generation fails"""
    repo_names = [repo_name for repo_name, _ in repo_dialogues]

    summary_dialogue = [
        "[S1]æ¬¢è¿æ”¶å¬ä»Šå¤©çš„GitHubçƒ­é—¨é¡¹ç›®podcastï¼ä»Šå¤©æˆ‘ä»¬å°†ä¸ºå¤§å®¶ä»‹ç»5ä¸ªæœ€å—å…³æ³¨çš„å¼€æºé¡¹ç›®ã€‚",
        "[S2]å¬èµ·æ¥å¾ˆexcitingå•Šï¼éƒ½æœ‰å“ªäº›æœ‰è¶£çš„é¡¹ç›®å‘¢ï¼Ÿ",
        f"[S1]ä»Šå¤©æˆ‘ä»¬ä¼šæ·±å…¥äº†è§£{', '.join(repo_names[:3])}ç­‰é¡¹ç›®ï¼Œå®ƒä»¬å„æœ‰ç‰¹è‰²ï¼Œæ¶µç›–äº†ä¸åŒçš„æŠ€æœ¯é¢†åŸŸã€‚",
        "[S2]å¤ªå¥½äº†ï¼è®©æˆ‘ä»¬ä¸€èµ·æ¥æ¢ç´¢è¿™äº›amazingçš„å¼€æºé¡¹ç›®å§ï¼",
        "[S1]æ²¡é”™ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°±é€ä¸€ä»‹ç»è¿™äº›é¡¹ç›®ï¼Œç›¸ä¿¡ä½ ä»¬ä¼šæœ‰å¾ˆå¤šæ”¶è·ã€‚Let's get started!",
    ]

    return summary_dialogue


def create_fallback_dialogue(repo_info: Dict[str, Any]) -> List[str]:
    """Create fallback dialogue based on repository information"""
    name = repo_info.get("name", "Unknown Repository")
    description = repo_info.get("description", "")
    language = repo_info.get("language", "")
    stars = repo_info.get("stargazers_count", 0)

    dialogue = [
        f"[S1]ä»Šå¤©æˆ‘ä»¬æ¥èŠèŠGitHubä¸Šä¸€ä¸ªæœ‰è¶£çš„é¡¹ç›®å«{name}ã€‚",
        f"[S2]å¬èµ·æ¥å¾ˆæœ‰æ„æ€ï¼Œè¿™ä¸ªprojectæ˜¯åšä»€ä¹ˆçš„å‘¢ï¼Ÿ",
    ]

    if description:
        dialogue.append(f"[S1]{description}")
        dialogue.append(f"[S2]é‚£è¿™ä¸ªé¡¹ç›®æœ‰ä»€ä¹ˆç‰¹åˆ«çš„åŠŸèƒ½å—ï¼Ÿ")

    if language:
        dialogue.append(f"[S1]è¿™ä¸ªprojectä¸»è¦æ˜¯ç”¨{language}å¼€å‘çš„ã€‚")

    if stars > 0:
        dialogue.append(f"[S2]çœ‹èµ·æ¥å¾ˆå—æ¬¢è¿å•Šï¼Œæœ‰{stars}ä¸ªstarsäº†ã€‚")
        dialogue.append(f"[S1]æ˜¯çš„ï¼Œè¯´æ˜è¿™ä¸ªé¡¹ç›®ç¡®å®æœ‰ä»·å€¼ï¼Œå€¼å¾—å¤§å®¶å…³æ³¨ã€‚")

    return dialogue


def generate_video_for_podcast(
    podcast_dialogue: List[str], repo_name: str, device: str, output_base_dir: Path
) -> Optional[Path]:
    """Generate a single video from podcast dialogue"""
    logger = setup_pipeline_logging()

    try:
        # Create unique output directory for this repo
        repo_output_dir = output_base_dir / f"repo_{repo_name.replace('/', '_')}"
        repo_output_dir.mkdir(parents=True, exist_ok=True)
        temp_dir = repo_output_dir / "temp"
        temp_dir.mkdir(exist_ok=True)

        logger.info(
            f"Generating video for {repo_name} with {len(podcast_dialogue)} dialogue segments"
        )

        # Initialize FireRedTTS2
        fireredtts2 = FireRedTTS2(
            pretrained_dir="./pretrained_models/FireRedTTS2",
            gen_type="dialogue",
            device=device,
        )

        prompt_wav_list = PROMPT_WAV_LIST

        prompt_text_list = PROMPT_TEXT_LIST

        # Generate TTS audio and SRT
        all_audio, srt_text = fireredtts2.generate_dialogue(
            text_list=podcast_dialogue,
            prompt_wav_list=prompt_wav_list,
            prompt_text_list=prompt_text_list,
            temperature=config["audio"].DEFAULT_TEMPERATURE,
            topk=config["audio"].DEFAULT_TOPK,
        )

        # Save audio and SRT files
        audio_file, _ = save_files(
            repo_output_dir, all_audio, srt_text, config["audio"].SAMPLE_RATE
        )

        # Generate video from SRT
        video_file = generate_video_from_srt(
            srt_text, audio_file, repo_output_dir, temp_dir
        )

        if video_file and video_file.exists():
            # Combine audio with video
            final_video = repo_output_dir / f"{repo_name.replace('/', '_')}_final.mp4"
            success = combine_audio_video(audio_file, video_file, final_video)

            if success and final_video.exists():
                logger.info(
                    f"Successfully generated video for {repo_name}: {final_video}"
                )
                return final_video
            else:
                logger.warning(
                    f"Audio/video combination failed for {repo_name}, returning silent video"
                )
                return video_file
        else:
            logger.error(f"Video generation failed for {repo_name}")
            return None

    except Exception as e:
        logger.error(f"Failed to generate video for {repo_name}: {e}")
        return None


def combine_videos(video_files: List[Path], output_file: Path, video_titles: Optional[List[str]] = None) -> bool:
    """Combine multiple videos into one final video and generate timestamp descriptions"""
    logger = setup_pipeline_logging()

    try:
        import subprocess

        # Filter out None values and ensure all files exist
        valid_videos = [v for v in video_files if v and v.exists()]

        if not valid_videos:
            logger.error("No valid video files to combine")
            return False

        if len(valid_videos) == 1:
            # If only one video, just copy it
            import shutil

            shutil.copy2(valid_videos[0], output_file)
            logger.info(f"Single video copied to {output_file}")

            # Generate simple timestamp for single video
            _generate_single_video_timestamps(output_file, valid_videos[0], video_titles)
            return True

        # Get video durations for timestamp generation
        video_durations = []
        for video in valid_videos:
            duration = _get_video_duration(video)
            video_durations.append(duration)

        # Create a text file listing all videos for ffmpeg
        concat_file = output_file.parent / "concat_list.txt"
        with open(concat_file, "w") as f:
            for video in valid_videos:
                f.write(f"file '{video.absolute()}'\n")

        # Use ffmpeg to concatenate videos
        cmd = [
            "ffmpeg",
            "-y",  # -y to overwrite output file
            "-f",
            "concat",
            "-safe",
            "0",
            "-i",
            str(concat_file),
            "-c",
            "copy",  # Copy streams without re-encoding
            str(output_file),
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        # Clean up concat file
        concat_file.unlink(missing_ok=True)

        if result.returncode == 0:
            logger.info(
                f"Successfully combined {len(valid_videos)} videos into {output_file}"
            )

            # Generate timestamp descriptions
            _generate_video_timestamps(output_file, valid_videos, video_durations, video_titles)

            return True
        else:
            logger.error(f"FFmpeg failed to combine videos: {result.stderr}")
            return False

    except Exception as e:
        logger.error(f"Failed to combine videos: {e}")
        return False


def _get_video_duration(video_path: Path) -> float:
    """Get video duration in seconds using ffprobe"""
    try:
        import subprocess

        cmd = [
            "ffprobe",
            "-v", "quiet",
            "-print_format", "json",
            "-show_format",
            str(video_path)
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            import json
            data = json.loads(result.stdout)
            duration = float(data["format"]["duration"])
            return duration
        else:
            return 0.0

    except Exception:
        return 0.0


def _format_timestamp(seconds: float) -> str:
    """Format seconds to MM:SS timestamp"""
    minutes = int(seconds // 60)
    seconds = int(seconds % 60)
    return f"{minutes:02d}:{seconds:02d}"


def _generate_video_timestamps(output_file: Path, video_files: List[Path], durations: List[float], titles: Optional[List[str]] = None) -> None:
    """Generate timestamp descriptions for combined video"""
    logger = setup_pipeline_logging()

    try:
        timestamp_file = output_file.parent / "timestamps.txt"

        current_time = 0.0
        timestamps = []

        for i, (video_file, duration) in enumerate(zip(video_files, durations)):
            # Extract title from video filename or use provided titles
            if titles and i < len(titles):
                title = titles[i]
            else:
                # Extract meaningful title from filename
                title = _extract_title_from_filename(video_file)

            timestamp_str = _format_timestamp(current_time)
            timestamps.append(f"{timestamp_str} {title}")

            current_time += duration

        # Write timestamps to file
        with open(timestamp_file, "w", encoding="utf-8") as f:
            f.write("è§†é¢‘æ—¶é—´è½´:\n\n")
            for timestamp in timestamps:
                f.write(f"{timestamp}\n")

        logger.info(f"Generated video timestamps: {timestamp_file}")

        # Also print to console for immediate visibility
        print(f"\nğŸ“ è§†é¢‘æ—¶é—´è½´:")
        for timestamp in timestamps:
            print(f"   {timestamp}")
        print(f"ğŸ“„ å®Œæ•´æ—¶é—´è½´æ–‡ä»¶: {timestamp_file}")

    except Exception as e:
        logger.error(f"Failed to generate video timestamps: {e}")


def _generate_single_video_timestamps(output_file: Path, video_file: Path, titles: Optional[List[str]] = None) -> None:
    """Generate timestamp for single video"""
    logger = setup_pipeline_logging()

    try:
        timestamp_file = output_file.parent / "timestamps.txt"

        # Extract title from video filename or use provided title
        if titles and len(titles) > 0:
            title = titles[0]
        else:
            title = _extract_title_from_filename(video_file)

        with open(timestamp_file, "w", encoding="utf-8") as f:
            f.write("è§†é¢‘æ—¶é—´è½´:\n\n")
            f.write(f"00:00 {title}\n")

        logger.info(f"Generated single video timestamp: {timestamp_file}")

        print(f"\nğŸ“ è§†é¢‘æ—¶é—´è½´:")
        print(f"   00:00 {title}")
        print(f"ğŸ“„ æ—¶é—´è½´æ–‡ä»¶: {timestamp_file}")

    except Exception as e:
        logger.error(f"Failed to generate single video timestamp: {e}")


def _extract_title_from_filename(video_file: Path) -> str:
    """Extract meaningful title from video filename"""
    filename = video_file.stem

    # Handle different naming patterns
    if "summary" in filename.lower():
        return "intro"
    elif "repo_" in filename:
        # Extract repo name from filename like "repo_user_project_final"
        parts = filename.split("_")
        if len(parts) >= 3:
            repo_name = "_".join(parts[1:-1])  # Remove 'repo_' prefix and '_final' suffix
            return repo_name.replace("_", "/")
        else:
            return filename.replace("repo_", "").replace("_", " ")
    else:
        # Clean up filename
        return filename.replace("_", " ").title()


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="AI Video Driver - Generate podcast-style videos from GitHub repositories"
    )

    parser.add_argument(
        "--repo-url", type=str, help="GitHub repository URL to generate content from"
    )

    parser.add_argument(
        "--style",
        type=str,
        choices=["educational", "casual", "technical", "marketing"],
        default="technical",
        help="Podcast style (default: technical)",
    )

    parser.add_argument(
        "--length",
        type=str,
        choices=["short", "medium", "long"],
        default="medium",
        help="Dialogue length (default: medium)",
    )

    parser.add_argument(
        "--github-token",
        type=str,
        help="GitHub API token (can also use GITHUB_TOKEN env var)",
    )

    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="Device for TTS model (default: cuda)",
    )

    parser.add_argument(
        "--output-name",
        type=str,
        default="auto_generated",
        help="Output directory name (default: auto_generated)",
    )

    parser.add_argument(
        "--multi-repo",
        action="store_true",
        help="Generate videos from top 5 trending repos and combine them",
    )

    parser.add_argument(
        "--video-only",
        action="store_true",
        help="Generate videos only without combining them",
    )

    return parser.parse_args()


def main():
    """Main pipeline execution with enhanced logging and error handling"""

    # Parse command line arguments
    args = parse_arguments()

    # Setup logging
    logger = setup_pipeline_logging()

    # Get GitHub token from args or environment
    github_token = args.github_token or os.getenv("GITHUB_TOKEN")

    # Configuration
    device = args.device
    logger.info(f"ğŸ–¥ï¸  Using device: {device}")

    # Handle multi-repo workflow
    if args.multi_repo:
        logger.info("ğŸ”„ Starting multi-repository video generation workflow")
        success = generate_multi_repo_content(
            args.style, args.length, device, args.output_name, github_token
        )
        if success:
            logger.info("âœ… Multi-repo workflow completed successfully")
        else:
            logger.error("âŒ Multi-repo workflow failed")
            sys.exit(1)
        return

    # Generate dialogue content based on arguments
    if args.repo_url:
        logger.info(f"ğŸ”— Generating content from repository: {args.repo_url}")
        text_list = generate_content_from_repo(
            args.repo_url, args.style, args.length, github_token
        )
    else:
        logger.info("ğŸ“ Using default FireRedTTS2 content")
        text_list = get_default_dialogue()

    prompt_wav_list = PROMPT_WAV_LIST
    prompt_text_list = PROMPT_TEXT_LIST

    logger.info(f"ğŸ“ Dialogue contains {len(text_list)} text segments")
    logger.info(f"ğŸ¤ Using {len(prompt_wav_list)} voice prompts")

    try:
        pipeline_start = time.time()

        # Step 1: Initialize FireRedTTS2
        with PipelineTimer("Initialize FireRedTTS2 model", logger):
            fireredtts2 = FireRedTTS2(
                pretrained_dir="./pretrained_models/FireRedTTS2",
                gen_type="dialogue",
                device=device,
            )

        # Step 2: Create output structure
        with PipelineTimer("Create output directory structure", logger):
            output_dir, temp_dir = create_output_structure(args.output_name)

        # Step 3: Generate TTS audio and SRT
        with PipelineTimer("Generate dialogue audio and subtitles", logger):
            all_audio, srt_text = fireredtts2.generate_dialogue(
                text_list=text_list,
                prompt_wav_list=prompt_wav_list,
                prompt_text_list=prompt_text_list,
                temperature=config["audio"].DEFAULT_TEMPERATURE,
                topk=config["audio"].DEFAULT_TOPK,
            )

        # Step 4: Save audio and SRT files
        with PipelineTimer("Save audio and subtitle files", logger):
            audio_file, srt_file = save_files(
                output_dir, all_audio, srt_text, config["audio"].SAMPLE_RATE
            )

        log_file_info(audio_file, logger, "ğŸµ")
        log_file_info(srt_file, logger, "ğŸ“„")

        # Step 5: Generate video from SRT
        with PipelineTimer("Generate video animation from subtitles", logger):
            video_file = generate_video_from_srt(
                srt_text, audio_file, output_dir, temp_dir
            )

        if video_file and video_file.exists():
            log_file_info(video_file, logger, "ğŸ¬")

            # Step 6: Combine audio with video
            with PipelineTimer("Combine audio and video", logger):
                final_video = output_dir / config["files"].FINAL_VIDEO_FILENAME
                success = combine_audio_video(audio_file, video_file, final_video)

            if success and final_video.exists():
                # Pipeline completed successfully
                total_time = time.time() - pipeline_start

                logger.info("=" * 60)
                logger.info("ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!")
                logger.info(f"ğŸ“ Output directory: {output_dir}")
                log_file_info(final_video, logger, "ğŸ¬")
                logger.info(f"â±ï¸  Total processing time: {total_time:.2f} seconds")
                logger.info("=" * 60)

                # Log all output files
                logger.info("ğŸ“‹ Generated files:")
                for file_path in output_dir.glob("*"):
                    if file_path.is_file():
                        log_file_info(file_path, logger, "   â€¢")

                print(f"\nğŸ¬ Final video: {final_video}")
                print(f"ğŸ“ All files: {output_dir}")

            else:
                logger.error("âŒ Failed to create final video with audio")
                logger.info(f"ğŸ¬ Silent video available: {video_file}")
                print(f"\nâš ï¸  Audio/video combination failed")
                print(f"ğŸ¬ Silent video: {video_file}")
                print(f"ğŸ“ Files: {output_dir}")

        else:
            logger.error("âŒ Video generation failed completely")
            print(f"\nâŒ Video generation failed")
            print(f"ğŸ“ Audio and SRT files: {output_dir}")

    except Exception as e:
        logger.error(f"ğŸ’¥ Pipeline failed with error: {e}", exc_info=True)
        print(f"\nğŸ’¥ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
