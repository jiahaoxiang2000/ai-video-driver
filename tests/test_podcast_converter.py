"""
Tests for PodcastConverter module.
"""

import unittest
import subprocess
import sys
import os

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai_video_driver.podcast_converter import PodcastConverter


class TestPodcastConverter(unittest.TestCase):
    """Test cases for PodcastConverter"""

    def setUp(self):
        """Set up test environment"""
        self.converter = PodcastConverter()

    def test_convert_to_podcast(self):
        """Test podcast conversion"""
        repo_content = {
            "name": "DeepResearch",
            "description": "Tongyi DeepResearch - an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Designed for long-horizon, deep information-seeking tasks.",
            "readme": """# Introduction

We present Tongyi DeepResearch, an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for long-horizon, deep information-seeking tasks. Tongyi DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and SimpleQA.

## Features

- âš™ï¸ Fully automated synthetic data generation pipeline: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.
- ğŸ”„ Large-scale continual pre-training on agentic data: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.
- ğŸ” End-to-end reinforcement learning: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples.
- ğŸ¤– Agent Inference Paradigm Compatibility: At inference, Tongyi DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode.

## Model Download

The model features 30B-A3B parameters with 128K context length and is available on HuggingFace and ModelScope.

## Quick Start

This guide provides instructions for setting up the environment and running inference scripts:

1. Environment Setup - Recommended Python version: 3.10.0
2. Installation - Install required dependencies with pip install -r requirements.txt
3. Prepare Evaluation Data - Create eval_data/ folder and place QA files in JSONL format
4. Configure the Inference Script - Modify run_react_infer.sh with model path and dataset
5. Run the Inference Script - Execute bash run_react_infer.sh

## Deep Research Agent Family

Tongyi DeepResearch has an extensive deep research agent family including WebWalker, WebDancer, WebSailor, WebShaper, WebWatcher, WebResearcher, ReSum, WebWeaver and more, all designed for advanced web navigation and information seeking tasks.""",
        }

        dialogue = self.converter.convert_to_podcast(repo_content, style="casual")
        print("Generated dialogue:")
        if dialogue:
            for i, line in enumerate(dialogue, 1):
                print(f"{i}: {line}")
        else:
            print("No dialogue generated")

        # Should either get real Claude response or fallback dialogue
        self.assertIsNotNone(dialogue)
        assert dialogue is not None  # Type guard
        self.assertGreater(len(dialogue), 0)
        # All lines should have speaker tags
        self.assertTrue(
            all(line.startswith("[S1]") or line.startswith("[S2]") for line in dialogue)
        )

    def test_parse_dialogue_response_valid(self):
        """Test parsing valid dialogue response"""
        response = """[S1]Hello, this is speaker one.
[S2]Hi there, this is speaker two.
[S1]Great to meet you!"""

        dialogue = self.converter._parse_dialogue_response(response)

        self.assertIsNotNone(dialogue)
        assert dialogue is not None  # Type guard
        self.assertEqual(len(dialogue), 3)
        self.assertEqual(dialogue[0], "[S1]Hello, this is speaker one.")
        self.assertEqual(dialogue[1], "[S2]Hi there, this is speaker two.")

    def test_parse_dialogue_response_mixed_format(self):
        """Test parsing dialogue with mixed format"""
        response = """[S1]Hello, this is speaker one.
This is a response without speaker tag.
[S2]Hi there, this is speaker two."""

        dialogue = self.converter._parse_dialogue_response(response)

        self.assertIsNotNone(dialogue)
        assert dialogue is not None  # Type guard
        self.assertEqual(len(dialogue), 3)
        self.assertTrue(dialogue[1].startswith("[S2]"))  # Should alternate speakers

    def test_parse_dialogue_response_insufficient(self):
        """Test parsing insufficient dialogue"""
        response = "[S1]Only one line"

        dialogue = self.converter._parse_dialogue_response(response)

        self.assertIsNone(dialogue)

    def test_validate_dialogue_format_valid(self):
        """Test dialogue format validation - valid"""
        dialogue = [
            "[S1]This is a valid dialogue segment.",
            "[S2]This is another valid segment.",
        ]

        is_valid = self.converter.validate_dialogue_format(dialogue)
        self.assertTrue(is_valid)

    def test_validate_dialogue_format_invalid_speaker(self):
        """Test dialogue format validation - invalid speaker"""
        dialogue = ["[S1]This is valid.", "[S3]This has invalid speaker tag."]

        is_valid = self.converter.validate_dialogue_format(dialogue)
        self.assertFalse(is_valid)

    def test_validate_dialogue_format_too_long(self):
        """Test dialogue format validation - too long"""
        long_text = "x" * 350  # Exceeds 300 character limit
        dialogue = [f"[S1]{long_text}"]

        is_valid = self.converter.validate_dialogue_format(dialogue)
        self.assertFalse(is_valid)

    def test_generate_summary_dialogue(self):
        """Test summary dialogue generation from multiple repositories"""
        summary_content = {
            "name": "GitHub Top 5 Trending Repositories Summary",
            "description": "Summary of top 5 trending repositories: DeepResearch, FireRedTTS2, Claude-Code, React-Native, TensorFlow",
            "readme": """Repository: DeepResearch
Key discussion points: [S1]ä»Šå¤©æˆ‘ä»¬æ¥èŠèŠä¸€ä¸ªå¾ˆå‰å®³çš„AI modelå«DeepResearchã€‚ [S2]å¬èµ·æ¥å¾ˆæœ‰æ„æ€ï¼Œè¿™ä¸ªmodelæœ‰ä»€ä¹ˆç‰¹åˆ«çš„åœ°æ–¹å‘¢ï¼Ÿ [S1]è¿™ä¸ªmodelæœ‰30.5 billion parametersï¼Œä½†æ˜¯æ¯ä¸ªtokenåªactivate 3.3 billionï¼Œä¸“é—¨designed for long-horizon information-seeking tasksã€‚

Repository: FireRedTTS2
Key discussion points: [S1]æ¥ä¸‹æ¥æˆ‘ä»¬èŠèŠFireRedTTS2ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆpowerfulçš„TTS systemã€‚ [S2]TTSæ˜¯ä»€ä¹ˆæ„æ€å•Šï¼Ÿ [S1]TTSå°±æ˜¯Text-to-Speechï¼ŒFireRedTTS2å¯ä»¥generate multi-speaker dialogueï¼Œè€Œä¸”supportè¶…è¿‡3åˆ†é’Ÿçš„conversational speechã€‚

Repository: Claude-Code
Key discussion points: [S1]ç„¶åæˆ‘ä»¬æ¥çœ‹çœ‹Claude-Codeï¼Œè¿™æ˜¯Anthropicæ¨å‡ºçš„coding assistantã€‚ [S2]è¿™ä¸ªè·Ÿå…¶ä»–çš„coding toolsæœ‰ä»€ä¹ˆä¸åŒå—ï¼Ÿ [S1]Claude-Code integratedäº†å¾ˆå¤šadvanced featuresï¼Œå¯ä»¥help developers write better code with AI assistanceã€‚""",
        }

        dialogue = self.converter._generate_summary_dialogue(summary_content)
        print("Generated summary dialogue:")
        if dialogue:
            for i, line in enumerate(dialogue, 1):
                print(f"{i}: {line}")
        else:
            print("No summary dialogue generated")

        # Should either get real AI response or None (if API fails)
        if dialogue is not None:
            self.assertGreater(len(dialogue), 0)
            # All lines should have speaker tags
            self.assertTrue(
                all(
                    line.startswith("[S1]") or line.startswith("[S2]")
                    for line in dialogue
                )
            )
            # Should validate format
            self.assertTrue(self.converter.validate_dialogue_format(dialogue))
            # Should be reasonably sized for an introduction
            self.assertGreaterEqual(len(dialogue), 4)  # At least 4 segments
            self.assertLessEqual(len(dialogue), 15)  # Not too many for intro


if __name__ == "__main__":
    unittest.main(verbosity=2)
